{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 175ms/step - accuracy: 0.1487 - loss: 3.8888 - val_accuracy: 0.1423 - val_loss: 2.6881 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 161ms/step - accuracy: 0.2594 - loss: 2.2572 - val_accuracy: 0.2333 - val_loss: 2.2319 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 195ms/step - accuracy: 0.3011 - loss: 1.9741 - val_accuracy: 0.2751 - val_loss: 2.0330 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 207ms/step - accuracy: 0.3746 - loss: 1.7999 - val_accuracy: 0.3481 - val_loss: 1.9015 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 209ms/step - accuracy: 0.4057 - loss: 1.6895 - val_accuracy: 0.3756 - val_loss: 1.7666 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 234ms/step - accuracy: 0.4331 - loss: 1.6270 - val_accuracy: 0.4486 - val_loss: 1.5519 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 179ms/step - accuracy: 0.4634 - loss: 1.5136 - val_accuracy: 0.4282 - val_loss: 1.6545 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 258ms/step - accuracy: 0.5146 - loss: 1.4027 - val_accuracy: 0.5096 - val_loss: 1.4507 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 173ms/step - accuracy: 0.5162 - loss: 1.3980 - val_accuracy: 0.5467 - val_loss: 1.3704 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 154ms/step - accuracy: 0.5741 - loss: 1.3088 - val_accuracy: 0.5837 - val_loss: 1.2706 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 166ms/step - accuracy: 0.6024 - loss: 1.2263 - val_accuracy: 0.6112 - val_loss: 1.2056 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.6065 - loss: 1.1936 - val_accuracy: 0.6100 - val_loss: 1.1976 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 154ms/step - accuracy: 0.6248 - loss: 1.1723 - val_accuracy: 0.5813 - val_loss: 1.2518 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.6029 - loss: 1.1517 - val_accuracy: 0.6495 - val_loss: 1.0962 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 157ms/step - accuracy: 0.6301 - loss: 1.0982 - val_accuracy: 0.6268 - val_loss: 1.1058 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 160ms/step - accuracy: 0.6561 - loss: 1.0606 - val_accuracy: 0.6471 - val_loss: 1.0512 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 157ms/step - accuracy: 0.6492 - loss: 1.0081 - val_accuracy: 0.6471 - val_loss: 1.1169 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - accuracy: 0.6589 - loss: 1.0101 - val_accuracy: 0.6423 - val_loss: 1.0321 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 158ms/step - accuracy: 0.6564 - loss: 1.0072 - val_accuracy: 0.6663 - val_loss: 0.9796 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.6729 - loss: 0.9406 - val_accuracy: 0.6507 - val_loss: 0.9952 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 154ms/step - accuracy: 0.6681 - loss: 0.9632 - val_accuracy: 0.6627 - val_loss: 0.9892 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.6750 - loss: 0.9382 - val_accuracy: 0.6495 - val_loss: 1.0688 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 160ms/step - accuracy: 0.6900 - loss: 0.9013 - val_accuracy: 0.6770 - val_loss: 0.9471 - learning_rate: 5.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 154ms/step - accuracy: 0.7044 - loss: 0.8508 - val_accuracy: 0.6986 - val_loss: 0.8769 - learning_rate: 5.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - accuracy: 0.7367 - loss: 0.7983 - val_accuracy: 0.7022 - val_loss: 0.8838 - learning_rate: 5.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 154ms/step - accuracy: 0.7306 - loss: 0.8121 - val_accuracy: 0.6902 - val_loss: 0.8936 - learning_rate: 5.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 157ms/step - accuracy: 0.7266 - loss: 0.7991 - val_accuracy: 0.6974 - val_loss: 0.8677 - learning_rate: 5.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.7206 - loss: 0.7844 - val_accuracy: 0.6866 - val_loss: 0.9078 - learning_rate: 5.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 156ms/step - accuracy: 0.7215 - loss: 0.8057 - val_accuracy: 0.7081 - val_loss: 0.8674 - learning_rate: 5.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 160ms/step - accuracy: 0.7383 - loss: 0.7613 - val_accuracy: 0.7057 - val_loss: 0.8468 - learning_rate: 5.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 157ms/step - accuracy: 0.7332 - loss: 0.7664 - val_accuracy: 0.6734 - val_loss: 0.9225 - learning_rate: 5.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 157ms/step - accuracy: 0.7292 - loss: 0.7779 - val_accuracy: 0.6794 - val_loss: 0.9124 - learning_rate: 5.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.7427 - loss: 0.7465 - val_accuracy: 0.7022 - val_loss: 0.8659 - learning_rate: 5.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.7369 - loss: 0.7413 - val_accuracy: 0.7081 - val_loss: 0.8370 - learning_rate: 2.5000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 157ms/step - accuracy: 0.7489 - loss: 0.7114 - val_accuracy: 0.7105 - val_loss: 0.8453 - learning_rate: 2.5000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - accuracy: 0.7560 - loss: 0.7013 - val_accuracy: 0.7105 - val_loss: 0.8188 - learning_rate: 2.5000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.7702 - loss: 0.6959 - val_accuracy: 0.7225 - val_loss: 0.8006 - learning_rate: 2.5000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - accuracy: 0.7521 - loss: 0.7065 - val_accuracy: 0.7177 - val_loss: 0.8247 - learning_rate: 2.5000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 156ms/step - accuracy: 0.7693 - loss: 0.6705 - val_accuracy: 0.7057 - val_loss: 0.8299 - learning_rate: 2.5000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - accuracy: 0.7599 - loss: 0.6927 - val_accuracy: 0.7153 - val_loss: 0.8530 - learning_rate: 2.5000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - accuracy: 0.7705 - loss: 0.6739 - val_accuracy: 0.7213 - val_loss: 0.8259 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 153ms/step - accuracy: 0.7789 - loss: 0.6522 - val_accuracy: 0.7213 - val_loss: 0.8147 - learning_rate: 1.2500e-04\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6895 - loss: 0.9049\n",
      "Test Loss: 0.9090, Test Accuracy: 0.6887\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.74      0.77      0.76       139\n",
      "        calm       0.53      0.62      0.57        50\n",
      "     disgust       0.63      0.62      0.63       156\n",
      "        fear       0.77      0.66      0.71       144\n",
      "   happiness       1.00      0.23      0.38        13\n",
      "       happy       0.80      0.63      0.70       134\n",
      "     neutral       0.75      0.80      0.77       133\n",
      "         sad       0.62      0.67      0.64       138\n",
      "     sadness       0.50      0.33      0.40         9\n",
      "    surprise       0.64      0.78      0.70       128\n",
      "\n",
      "    accuracy                           0.69      1044\n",
      "   macro avg       0.70      0.61      0.63      1044\n",
      "weighted avg       0.70      0.69      0.69      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set paths\n",
    "Root_dir = 'C:/Users/User/Desktop/new/Dataset'\n",
    "Crema_path = Root_dir + \"/Crema/\" \n",
    "Ravdess_path = Root_dir + \"/Ravdess/\"\n",
    "Savee_path = Root_dir + \"/Savee/\"\n",
    "Tess_path = Root_dir + \"/Tess/\"\n",
    "\n",
    "# Limit the number of samples to 500 from each dataset for faster training\n",
    "Crema_dir_list = os.listdir(Crema_path)[:500]\n",
    "Ravdess_dir_list = os.listdir(Ravdess_path)[:500]\n",
    "Savee_dir_list = os.listdir(Savee_path)[:500]\n",
    "Tess_dir_list = os.listdir(Tess_path)[:500]\n",
    "\n",
    "# Load and preprocess datasets\n",
    "def load_crema_data(Crema_path, Crema_dir_list):\n",
    "    emotions_crema = []\n",
    "    paths_crema = []\n",
    "    for it in Crema_dir_list:\n",
    "        paths_crema.append(Crema_path + it)\n",
    "        part = it.split('_')\n",
    "        if part[2] == 'SAD':\n",
    "            emotions_crema.append('sad')\n",
    "        elif part[2] == 'ANG':\n",
    "            emotions_crema.append('angry')\n",
    "        elif part[2] == 'DIS':\n",
    "            emotions_crema.append('disgust')\n",
    "        elif part[2] == 'FEA':\n",
    "            emotions_crema.append('fear')\n",
    "        elif part[2] == 'HAP':\n",
    "            emotions_crema.append('happy')\n",
    "        elif part[2] == 'NEU':\n",
    "            emotions_crema.append('neutral')\n",
    "        else:\n",
    "            emotions_crema.append('Unknown')\n",
    "    \n",
    "    emotions_crema_df = pd.DataFrame(emotions_crema, columns=['Emotions'])\n",
    "    path_crema_df = pd.DataFrame(paths_crema, columns=['Path'])\n",
    "    return pd.concat([emotions_crema_df, path_crema_df], axis=1)   \n",
    "\n",
    "def load_ravdess_data(Ravdess_path, Ravdess_dir_list):\n",
    "    emotions_ravdess = []\n",
    "    path_ravdess = []\n",
    "    for it in Ravdess_dir_list:\n",
    "        actor = os.listdir(Ravdess_path + it)[:500]\n",
    "        for file in actor:\n",
    "            part = file.split('.')[0]\n",
    "            part = part.split('-')\n",
    "            emotions_ravdess.append(int(part[2]))\n",
    "            path_ravdess.append(Ravdess_path + it + '/' + file)\n",
    "    \n",
    "    emotion_ravdess_df = pd.DataFrame(emotions_ravdess, columns=['Emotions'])\n",
    "    path_ravdess_df = pd.DataFrame(path_ravdess, columns=['Path'])\n",
    "    Ravdess_df = pd.concat([emotion_ravdess_df, path_ravdess_df], axis=1)\n",
    "    Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "    return Ravdess_df\n",
    "\n",
    "def load_savee_data(Savee_path, Savee_dir_list):\n",
    "    emotions_savee = []\n",
    "    path_savee = []\n",
    "    for it in Savee_dir_list:\n",
    "        path_savee.append(Savee_path + it)\n",
    "        part = it.split('_')[1]\n",
    "        part = part[:-6]\n",
    "        if part == 'a':\n",
    "            emotions_savee.append('angry')\n",
    "        elif part == 'd':\n",
    "            emotions_savee.append('disgust')\n",
    "        elif part == 'f':\n",
    "            emotions_savee.append('fear')\n",
    "        elif part == 'h':\n",
    "            emotions_savee.append('happiness')\n",
    "        elif part == 'n':\n",
    "            emotions_savee.append('neutral')\n",
    "        elif part == 'sa':\n",
    "            emotions_savee.append('sadness')\n",
    "        elif part == 'su':\n",
    "            emotions_savee.append('surprise')\n",
    "        else:\n",
    "            emotions_savee.append('Unknown')\n",
    "    \n",
    "    emotion_savee_df = pd.DataFrame(emotions_savee, columns=['Emotions'])\n",
    "    path_savee_df = pd.DataFrame(path_savee, columns=['Path'])\n",
    "    return pd.concat([emotion_savee_df, path_savee_df], axis=1)\n",
    "\n",
    "def load_tess_data(Tess_path, Tess_dir_list):\n",
    "    emotions_tess = []\n",
    "    path_tess = []\n",
    "    for it in Tess_dir_list:\n",
    "        directories = os.listdir(Tess_path + '/' + it)[:500]\n",
    "        for file in directories:\n",
    "            part = file.split('.')[0]\n",
    "            part = part.split('_')[2]\n",
    "            if part == 'ps':\n",
    "                emotions_tess.append('surprise')\n",
    "            else:\n",
    "                emotions_tess.append(part)\n",
    "            path_tess.append(Tess_path + it + '/' + file)\n",
    "    \n",
    "    emotion_tess_df = pd.DataFrame(emotions_tess, columns=['Emotions'])\n",
    "    path_tess_df = pd.DataFrame(path_tess, columns=['Path'])\n",
    "    return pd.concat([emotion_tess_df, path_tess_df], axis=1)\n",
    "\n",
    "Crema_df = load_crema_data(Crema_path, Crema_dir_list)\n",
    "Ravdess_df = load_ravdess_data(Ravdess_path, Ravdess_dir_list)\n",
    "Savee_df = load_savee_data(Savee_path, Savee_dir_list)\n",
    "Tess_df = load_tess_data(Tess_path, Tess_dir_list)\n",
    "\n",
    "# Merging all datasets\n",
    "data_path = []\n",
    "data_emotion = []\n",
    "\n",
    "def append_data(dataset):\n",
    "    for path, emotion in zip(dataset.Path, dataset.Emotions):\n",
    "        data_path.append(path)\n",
    "        data_emotion.append(emotion)\n",
    "\n",
    "append_data(Crema_df)\n",
    "append_data(Ravdess_df)\n",
    "append_data(Savee_df)\n",
    "append_data(Tess_df)\n",
    "\n",
    "All_data = pd.DataFrame(data_emotion, columns=['Emotions'])\n",
    "All_data['Path'] = data_path\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "All_data['Emotion_Label'] = label_encoder.fit_transform(All_data['Emotions'])\n",
    "\n",
    "# Split data\n",
    "X = All_data['Path'].values\n",
    "y = All_data['Emotion_Label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=61)\n",
    "\n",
    "# Feature Extraction Functions\n",
    "def extract_features(file_path):\n",
    "    signal, sr = librosa.load(file_path, sr=44100)\n",
    "    zcr = np.mean(librosa.feature.zero_crossing_rate(y=signal).T, axis=0)\n",
    "    chroma_stft = np.mean(librosa.feature.chroma_stft(y=signal, sr=sr).T, axis=0)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    rms = np.mean(librosa.feature.rms(y=signal).T, axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=signal, sr=sr).T, axis=0)\n",
    "    return np.hstack([zcr, chroma_stft, mfcc, rms, mel])\n",
    "\n",
    "def parallel_feature_extraction(file_paths):\n",
    "    return Parallel(n_jobs=-1)(delayed(extract_features)(file) for file in file_paths)\n",
    "\n",
    "# Extract features and save them to disk\n",
    "if not os.path.exists('X_train_features.npy') or not os.path.exists('X_test_features.npy'):\n",
    "    X_train_features = np.array(parallel_feature_extraction(X_train))\n",
    "    X_test_features = np.array(parallel_feature_extraction(X_test))\n",
    "    np.save('X_train_features.npy', X_train_features)\n",
    "    np.save('X_test_features.npy', X_test_features)\n",
    "else:\n",
    "    X_train_features = np.load('X_train_features.npy')\n",
    "    X_test_features = np.load('X_test_features.npy')\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_features = scaler.fit_transform(X_train_features)\n",
    "X_test_features = scaler.transform(X_test_features)\n",
    "\n",
    "# Reshape features for GRU input\n",
    "X_train_features = np.expand_dims(X_train_features, axis=2)\n",
    "X_test_features = np.expand_dims(X_test_features, axis=2)\n",
    "\n",
    "# Define Model\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_features.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    GRU(128, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    GRU(64, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=0.00001)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    X_train_features, y_train, \n",
    "    epochs=50, batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate Model\n",
    "loss, accuracy = model.evaluate(X_test_features, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification Report\n",
    "y_pred = model.predict(X_test_features)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_test, y_pred_labels, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
